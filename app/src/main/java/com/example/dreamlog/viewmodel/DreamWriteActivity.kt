package com.example.dreamlog.viewmodel

import android.Manifest
import android.content.Intent
import android.content.pm.PackageManager
import android.graphics.Bitmap
import android.graphics.BitmapFactory
import android.os.Bundle
import android.widget.Toast
import androidx.activity.result.ActivityResultLauncher
import androidx.activity.result.contract.ActivityResultContracts
import androidx.appcompat.app.AppCompatActivity
import androidx.core.content.ContextCompat
import com.example.dreamlog.databinding.ItemDreamBinding
import com.example.dreamlog.util.camera.CameraHelper
import com.example.dreamlog.util.EmotionAnalyzer
import com.example.dreamlog.util.camera.CameraHelper.rotateBitmapIfRequired
import java.io.File
import com.example.dreamlog.api.GptRetrofitInstance
import com.example.dreamlog.model.ChatRequest
import com.example.dreamlog.model.Message
import com.example.dreamlog.model.ChatResponse


class DreamWriteActivity : AppCompatActivity() {

    private lateinit var binding: ItemDreamBinding

    private lateinit var cameraLauncher: ActivityResultLauncher<Intent>
    private lateinit var cameraPermissionLauncher: ActivityResultLauncher<String>
    private var photoFile: File? = null
    private lateinit var imageBitmap: Bitmap


    override fun onCreate(savedInstanceState: Bundle?) {
        super.onCreate(savedInstanceState)
        binding = ItemDreamBinding.inflate(layoutInflater)
        setContentView(binding.root)
        binding.btnGenerateInterpretation.setOnClickListener {
            val userDream = binding.editDream.text.toString()

            if (userDream.isBlank()) {
                Toast.makeText(this, "ë¨¼ì € ê¿ˆì„ ì…ë ¥í•˜ì„¸ìš”!", Toast.LENGTH_SHORT).show()
                return@setOnClickListener
            }

            binding.textGptResult.text = "GPT í•´ì„ ì¤‘..."

            val request = ChatRequest(
                messages = listOf(
                    Message(role = "system", content = "ë„ˆëŠ” ê¿ˆ í•´ì„ ì „ë¬¸ê°€ì•¼. ì‚¬ìš©ìê°€ ë§í•œ ê¿ˆì„ ì‹¬ë¦¬í•™ì ìœ¼ë¡œ ë¶„ì„í•´ì„œ ì˜ë¯¸ë¥¼ ì„¤ëª…í•´ì¤˜."),
                    Message(role = "user", content = userDream)
                )
            )

            GptRetrofitInstance.api.getChatCompletion(request).enqueue(object : retrofit2.Callback<ChatResponse> {
                override fun onResponse(call: retrofit2.Call<ChatResponse>, response: retrofit2.Response<ChatResponse>) {
                    if (response.isSuccessful) {
                        val gptReply = response.body()?.choices?.firstOrNull()?.message?.content
                        binding.textGptResult.text = gptReply ?: "GPTì˜ ì‘ë‹µì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."
                    } else {
                        binding.textGptResult.text = "GPT ì‘ë‹µ ì‹¤íŒ¨: ${response.code()}"
                    }
                }

                override fun onFailure(call: retrofit2.Call<ChatResponse>, t: Throwable) {
                    binding.textGptResult.text = "GPT ìš”ì²­ ì‹¤íŒ¨: ${t.localizedMessage}"
                }
            })
        }


        // ğŸ“¸ ì¹´ë©”ë¼ ì‹¤í–‰ í›„ ê²°ê³¼ ì²˜ë¦¬
        cameraLauncher = registerForActivityResult(ActivityResultContracts.StartActivityForResult()) {
            CameraHelper.previewImage(binding.imagePreview)
        }

        // ğŸ“¸ ê¶Œí•œ ìš”ì²­ ê²°ê³¼ ì²˜ë¦¬
        cameraLauncher = registerForActivityResult(ActivityResultContracts.StartActivityForResult()) {
            val path = CameraHelper.getCurrentPhotoPath()
            if (path != null) {
                val rawBitmap = BitmapFactory.decodeFile(path)
                val correctedBitmap = rotateBitmapIfRequired(path, rawBitmap) // â­ íšŒì „ ë³´ì •
                imageBitmap = correctedBitmap
                binding.imagePreview.setImageBitmap(correctedBitmap)
            } else {
                Toast.makeText(this, "ì´ë¯¸ì§€ë¥¼ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤", Toast.LENGTH_SHORT).show()
            }
        }


        // ğŸ“¸ ì¹´ë©”ë¼ ë²„íŠ¼ í´ë¦­
        binding.btnOpenCamera.setOnClickListener {
            if (ContextCompat.checkSelfPermission(this, Manifest.permission.CAMERA)
                == PackageManager.PERMISSION_GRANTED) {
                photoFile = CameraHelper.dispatchTakePictureIntent(this, cameraLauncher)
            } else {
                cameraPermissionLauncher.launch(Manifest.permission.CAMERA)
            }
        }
        // ëª¨ë¸ ì´ˆê¸°í™” (onCreateì—ì„œ ë”± í•œ ë²ˆ)
        EmotionAnalyzer.initModel(this)

        // ì‚¬ì§„ì„ ì°ì€ ë’¤ imageBitmapì— ì €ì¥í•´ë†¨ë‹¤ê³  ê°€ì •í•˜ê³ ,
        // ê°ì •ë¶„ì„ ë²„íŠ¼ í´ë¦­ ì‹œ ë¶„ì„ ìˆ˜í–‰
        binding.btnAnalyzeEmotion.setOnClickListener {
            val emotion = EmotionAnalyzer.analyze(imageBitmap)
            binding.textEmotionResult.text = "ê°ì • ë¶„ì„ ê²°ê³¼: $emotion"
        }
    }
}
